{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Python\n",
    "\n",
    "\n",
    "For this course, we are going to use Jupyter notebook as our environment for developing Python code.\n",
    "refer to https://jupyter.readthedocs.io/en/latest/content-quickstart.html on the instructions how to install it, the easiest way is to install from Anaconda (https://www.anaconda.com/download/) website, make sure you install with Python 3.6.\n",
    "\n",
    "Also, it is good for the students who are not familiar with python (or they need a quick refreshment) to follow Jim Bagrow tutorial http://bagrow.com/ds1/whirlwindtourpython/00-Title.html. \n",
    "\n",
    "All the assignments to be written in Python 3.6 and can be run using Jupyter on one of the following Internet browsers (Chrome, Safari or Firefox), these are the browsers that officially supported by jupyter.\n",
    "\n",
    "<u> Note: for this assignment, submit your local copy of this page, running on IPython. Submit the file to Blackboard under Assignment3 using this file format:</u> <b>Yourfirstname_lastname_Assignment3.ipynb. Marks might be deducted if you do not follow the submission steps</b> \n",
    "\n",
    "#### <b>Deadline</b>: <u>Friday, Oct-15-2020 11:59 PM - NO EXTENSION.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn utilities\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Prepare the data, 15 Pts, 5 each\n",
    "\n",
    "*<strong>Q1)</strong> Use the sklearn load_digits() function to collect your data. <br>- You will be using this data for the entire assignment. <br>- Using the .data and .features attributes of this dataset and create a pandas dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q2)</strong> We want to be able to visualize what this data actually looks like.<br>- Use matplotlib.pyplot's imshow function to display the first five items in our dataset. <br>- Be sure to include the target value with these five images.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q3)</strong> Our data currently exists in a very high dimensional space. <br>- Reduce the data to a two dimensional space using principle component analysis. <br>- Once this data is transformed, create a scatter plot with different colors for different classes of data-points.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q4) We need to split our data into two groups in order to validate model performance and generalization ability. <br> - Use the sklearn train_test_split function to obtain training data and testing data. <br>- Important: you must use a test size of 0.25 and a random_state of 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression, 30 Pts, 10 each\n",
    "*<strong>Q5)</strong> Create a logistic regression model.<br>- Create a LogisticRegression object which can be imported from sklearn's linear_model module.<br>- Call the .fit() function on your model with x_train and y_train as parameters.<br>- Call the .predict() function on your model with x_test as a parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q6)</strong> Visualize the confusion matrix for this model<br>- Use sklearn's confusion matrix function to obtain a confusion matrix in np.array format<br>- Display this confusion matrix as a pandas DataFrame (with target class names in the columns and index fields).<br>- Display this confusion matrix as a heatmap using matplotlib.pyplot's .imshow() function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q7</strong> Lets examine how well our model performed. <br>- Create a function to calculate the precision values for all classes from the calculated confusion matrix.<br>- Create a function to calculate the recall values for all classes calculated confusion matrix.<br>- Use sklearn's classification_report as a reference for \"correct\" precision and recall values.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Support Vector Machine, 20 Pts, 10 each\n",
    "*<strong>Q8)</strong> Build an SVM classification model.<br>- Create an SVC object which can be imported from sklearn's svm module.<br>- Call the .fit() function on your model with x_train and y_train as parameters.<br>- Call the .predict() function on your model with x_test as a parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q9)</strong> Visualize the confusion matrix for this model<br>- Use sklearn's confusion matrix function to obtain a confusion matrix in np.array format<br>- Display this confusion matrix as a pandas DataFrame (with target class names in the columns and index fields).<br>- Display this confusion matrix as a heatmap using matplotlib.pyplot's .imshow() function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q10)</strong> Compare your SVM model to your regression model.<br>- Create a function to obtain useful metrics for your SVM's performance<br>- How does this performance compare to that of the regression model? (and explain why this might be)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Trees, 35 Pts, 7 each\n",
    "*<strong>Q11)</strong> Build an decision tree classification model.<br>- Create a DecisionTreeClassifier object which can be imported from sklearn's tree module.<br>- Call the .fit() function on your model with x_train and y_train as parameters.<br>- Call the .predict() function on your model with x_test as a parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q12)</strong> Visualize the confusion matrix for this model<br>- Use sklearn's confusion matrix function to obtain a confusion matrix in np.array format<br>- Display this confusion matrix as a pandas DataFrame (with target class names in the columns and index fields).<br>- Display this confusion matrix as a heatmap using matplotlib.pyplot's .imshow() function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q13)</strong> Build an random forest classification model.<br>- Create a RandomForestClassifier object which can be imported from sklearn's tree module.<br>- Call the .fit() function on your model with x_train and y_train as parameters.<br>- Call the .predict() function on your model with x_test as a parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q14)</strong> Visualize the confusion matrix for this model<br>- Use sklearn's confusion matrix function to obtain a confusion matrix in np.array format<br>- Display this confusion matrix as a pandas DataFrame (with target class names in the columns and index fields).<br>- Display this confusion matrix as a heatmap using matplotlib.pyplot's .imshow() function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q15)</strong> How does the parameter n_estimators effect model performance?<br> - Write a for loop to iterate through many different sizes of trees.<br>- Graph and report your findings.* <br>- use gridsearch sklearn function to find the best n_estimators.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate Student's Problem, 40Pts, 10 for each\n",
    "(Or extra credit for undergraduates)<br><br>*<strong>Q1)</strong> Load mnist and create a baseline RandomForest model<br>- Load the mnist dataset from the keras datasets library (or find the dataset online and import it with your method of choice).<br>- Transform the shape of your input data from (len(data), 28, 28) to (len(data), 28 * 28).<br>- Create a RandomForestClassifier, train on your training data, and obtain an accuracy score with your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q2)</strong> Create a \"Forest\" of DecisionTreeClassifiers<br>- Create a list of n DecisionTreeClassifier objects, where n is the same number of trees as your RandomForestClassifier above.<br>- Loop through your newly created forest and train all of your trees individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Def: Prediction Confidence</strong><br>Given a set of predictions of classes (0,1,...,n), Confidence of class i = the number of times i occurs in your set of predictions divided by the total number of len(set of predictions).<br><br>EX1:<br>predictions = [1, 0, 2, 1, 1] (You can think of this as a forest with n_estimators = 5 for one instance of test data)<br>prediction_confidence_per_class = [.2, .6, .2] (percent of predictions equal to class i)<br><br>EX2:<Br>predictions = [[1, 3, 3, 3, 3, 3, 1, 1, 1, 3], [2, 0, 2, 2, 2, 2, 2, 2, 2, 0]] (for two instances, n_estimators=10)<br>prediction_confidence_per_class = [[0, .4, 0, .6], [.2, 0, .8, 0]]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q3)</strong> Access the predictions from all of your trees and calculate prediction confidence<br>- Run the .predict() function on your test data for each tree in your forest. (you should get data of shape (len(x_test), n_estimators)<br>- Transform your raw predictions into a count of predictions for each class. (should be of shape (len(x_test), n_classes)<br>- Transform your prediction count data into prediction confidence as explained above. (should be of shape (len(x_test), n_classes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Q4)</strong> Find your ensemble accuracy<br>- For all test data, make an ensemble prediction (Hint: it has something to do with your confidence values).<br>- Obtain an accuracy score and compare it to your RandomForestClassifier's score above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
